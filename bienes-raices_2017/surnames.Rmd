---
title: "Surnames"
output:
  html_document:
    highlight: zenburn
    self_contained: false
    css: surnames.css
    df_print: paged
    theme: null
    includes:
      in_header: header.html
      before_body: prefix.html
      after_body: suffix.html
    # code_folding: show
  # github_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  eval = FALSE,
  collapse = TRUE,
  cache = TRUE,
  cache.comments = FALSE,
  out.width = "70%",
  fig.align = 'center',
  fig.width = 6,
  fig.asp = 0.618, # 1 / phi
  fig.show = "hold"
)
```

We'd like to study the genealogy
of the agropastoralist communities
in the Coquimbo region (Chile)
and see to what extent the evolution
of the different wealth inheritance
and land tenure norms in these communities
can be explained by their genealogy.


## Downloading the files with the data

The website of the
[Oficina Tecnica de Comunidades Agricolas](http://www.comunidadesagricolas.cl/) (OTCA)
hosts the registry of commoners
for all Agricultural Communities
in the Coquimbo and Atacama regions (Chile).
The OTCA collected the registry of commoners
of some of the Agricultural Communities
in years 2008, 2009, 2010, and 2011.
For this reason,
a community can have its registry of commoners
available as a pdf file on the website
for some, all or none of those years.
We crawl the website to compile
a list of the communities for which there is data
together with the years from which their data is available
and the url of their latest pdf file.
This is done by the `download_pdfs` function
in `download-pdfs.R`,
which then proceeds to download the pdf files
in a `pdfs` folder that it creates.

```{r download, cache=TRUE}
source('download-pdfs.R')
download_pdfs()
```


## Extracting the data

After downloading the files,
we want to extract the tables contained in them as dataframes.

```{r read, cache=TRUE}
source('extract-pdfs.R')
commoners_untidy <- read_pdfs()
```

This function tries to read the pdf file
using several different methods in sequence
and accepts the first method that returns a valid dataframe.
The sequence of methods is determined by
the `method` parameter,
which in its default value dictates the following order:

1. [tabulizer](https://github.com/ropensci/tabulizer)
2. [tabula](https://github.com/tabulapdf/tabula-java/)
3. pdftohtml (not implemented yet)
4. pdftotext (not implemented yet)

This is needed because no method so far is infallible.
<!-- For the purpose of this function, -->
In the context of this function,
a valid dataframe is an object
for which `is.data.frame()` returns `TRUE`,
contains 5 columns,
is not empty,
and the commoner ids (second column) start from 1
and increase by 0, 1, or 2 with each row.

Unfortunately, many pdf files do not return
a valid dataframe with any method.
This is either because a) two columns are too close together
and so are detected as one,
or because b) the last column didn't fit in a portrait page
and so appears in the last pages.
The latter was solved
by transcribing the pdf files into csvs by hand
or, in some lucky cases where the last column is trivial,
by adding the last column to
the 4-column extracted matrix.
The former, on the other hand,
can be solved programmatically by
a1) separating the commoner number from the name
when the second and third columns were merged
(see function `format_table` of `extract-pdfs.R`),
and by
a2) separating the first name from the surname 
when the third and fourth columns were merged
(see function `fix_names`).
To make (a2) possible,
compound names had to be merged into one word
by substituting an underscore for the space,
e.g. Del Rosario into Del_Rosario
(see function `fix_compound_names`).
<!-- The former can be solved by programmatic means -->
<!-- (see for instance the code in -->
<!--  function `format_table` of `extract-pdfs.R`, -->
<!--  although more is needed to fully solve the first issue) -->
<!-- but the latter must be solved -->
<!-- by transcribing the pdf files into csvs by hand. -->

The dataframes so extracted have several other issues as well.
They are presented in the following table
together with the function that solves each issue.

------------------------------------------------------------------
            Issue                                    Function
----------------------------------------------- ------------------
The same name appears with and
without diacritic marks.                        `remove_accents`

Commoners that were removed
from the registry sometimes appear              `remove_nonpeople`
as a commoner with name "eliminado"
(Spanish for "removed").

Sometimes a company or community owns
a right in a community but they can't           `remove_nonpeople`
be subject to the surname analysis
we will perform.

Sometimes only the initial of a name            `remove_initials`
or surname appears.

Successions were sometimes
annotated as a ficticious extra commoner        `remove_sucesiones`
before the list of commoners
in the succession.

Only the first commoner in a succession
shows the rights of the whole succession        `fix_rights`
next to it.
This number had to be divided by
all commoners in the succession.

Sometimes commoners appear more than once       `fix_repeated`
in a community when they own more than
one right.
------------------------------------------------------------------

Finally, some extra information was added
to this dataframe to later be able to
compute the gender bias (`assign_sex`)
and do aggregated analyses per commune and province
(`add_commune` and `add_province_and_region`).
Also, in order to facilitate the surname analysis,
the first surname (received from the father)
and the second surname (received from the mother)
were split.

All these functions and a few other case-by-case tweaks
are run by the `extract_pdfs` function.

```{r extract, cache=TRUE, dependson="read"}
commoners <- extract_pdfs(commoners_untidy)
```


## Analysis

With the data we collected in the previous step
we can now run some analyses.
The first analysis we would like to see
is a dendrogram (i.e. a tree) of the communities
according to the similarity of
their distribution of surnames.

There are different metrics of
the similarity of surname distributions.
One commonly used is Hedrick's formula,
which computes the similarity $H_{ij}$
of a community $i$ and $j$ as:

\[ H_{ij} = \frac{ \sum_s s_i s_j }{
     \frac{1}{2} (\sum_s s_i^2 + \sum_s s_j^2) } \]

where $s \in \mathbb{N}^C$ is the vector
containing the frecuencies $s_i$
of a given surname in community $i \in C$.
Dually, one can see a community
as a surname-indexed vector
$i \in \mathbb{N}^S$
with elements $i_s = s_i$.
We can then rewrite $H_{ij}$ as

\[ H_{ij} = \frac{ 2 \, (i \cdot j) }{
     i \cdot i + j \cdot j } \]

where $i$ and $j$ are surname-indexed vectors as above
and $i \cdot j$ is their dot product.
Note that $0 \leq H_{ij} \leq 1$ because
$\newcommand{\norm}[1]{\left\lVert #1 \right\rVert}$

1) $i \cdot i = \norm{i}^2$ and $j \cdot j = \norm{j}^2$
   are both nonnegative;
2) all coordinates of $i$ and $j$ are nonnegative,
   so the angle between them can be at most $90^\circ$
   and $i \cdot j$ is nonnegative; and
3) the maximum value for $i \cdot j$ is obtained
   when $i$ and $j$ are co-linear,
   in which case $i \cdot j = \norm{i} \norm{j}$
   and $2 \norm{i} \norm{j} \leq \norm{i}^2 + \norm{j}^2$.

One then obtains a metric $G_{ij} = 1 - H_{ij}$ on $\mathbb{N}^S$.

1) non-negativity: $G_{ij} \geq 0$ since $H_{ij} \leq 1$
2) identity of indiscernibles: $G_{ij} = 0$ iff $i = j$
   because $H_{ij} = 1$ only when
   $2 \norm{i} \norm{j} = \norm{i}^2 + \norm{j}^2$
3) symmetry: $G_{ij} = G_{ji}$
   as the definition of $H_{ij}$ is symmetric
4) triangle inequality: $G_{ik} \leq G_{ij} + G_{jk}$

TODO: prove triangle inequality.

As a metric on the non-normalised vectors,
$G_{ij}$ has the property that if $i$ and $j$ are co-linear
but not of the same magnitude,
then $G_{ij}$ is strictly greater than 0.
In other words, two communities with the same
relative composition (ie probability distribution) of surnames
but different number of commoners
will have $H_{ij} < 1$ and thus $G_{ij} > 0$.
This scale dependence is unfortunate.
Instead we would like to have a scale-independent metric.
An interesting scale-independent pseudometric is $1$ minus
the cosine of the angle $\theta$ between vectors $i$ and $j$
in the euclidean space $\mathbb{R}^S$.

\[ D_{ij} = 1 - \cos \theta = 1 - \frac{ i \cdot j }{
     \sqrt{i \cdot i} \sqrt{j \cdot j} } =
   1 - \frac{ i \cdot j }{ \norm{i} \norm{j} } \]

Despite the similarities between $D_{ij}$ and $H_{ij}$,
$D_{ij}$ is equal to $1$ whenever $i$ and $j$
have the same relative composition of surnames.
This implies that $D_{ij}$ is not a metric on $\mathbb{R}^S$
but a metric on the normalised vectors $i/\norm{i}$.
As before, we have $0 \leq D_{ij} \leq 1$.

Expressing $i \cdot j$ in terms of the cosine of $\theta$,
one can rewrite $H_{ij}$ yet again as

\[ H_{ij} = \frac{ 2 \, (i \cdot j) }{ \norm{i}^2 + \norm{j}^2 } =
   \frac{ 2 \cos \theta \norm{i} \norm{j} }{
   \norm{i}^2 + \norm{j}^2 } =
   \frac{ 2 \cos \theta }{ \frac{\norm{i}}{\norm{j}} +
   \frac{\norm{i}}{\norm{j}} } \]

Notice that whenever $i$ and $j$ are normalised
(ie $\norm{i} = 1 = \norm{j}$) then $H_{ij} = \cos \theta$.
Interestingly, Hedrick's similarity is usually
computed on the normalised vectors.
<!-- Still, I have no geometric intution -->
<!-- for these expressions in the general case. -->

The distance between two communities may also be computed
by using any standard metric for probability distributions
on the normalised vectors,
eg [Wasserstein](https://en.wikipedia.org/wiki/Wasserstein_metric).
For the Wasserstein metric see R package
[transport](https://www.rdocumentation.org/packages/transport/versions/0.9-4).

From the distance matrix obtained using any of the methods above
we would like to build a dendrogram.
The simplest methods are hierarchical clustering methods,
of which there are several varieties depending on the way
in which distances between groups of communities are computed.
The method can be summarised as follows:

1) put each element into its own group
2) the distance between such singleton groups is
   taken directly from the distance matrix
3) join the closest groups into a new group
4) compute the distance between the new group and the rest
   using a function that takes as input the distance vectors
   of each of the elements in the group

It'd be nice to make a heatmap matrix
indicating how similar two dendrograms computed with
different distance and clustering methods are.


```{r dendro, cache=TRUE, dependson="extract"}
source('analysis.R')
```






